{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52ecd561-e52b-4f76-87ca-87baacc93b10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "| Version | Date       | Developer | Remark             |\n",
    "|---------|------------|-----------|--------------------|\n",
    "| 1.0     | Feb-1-2025 | Johnson | Initial version:developed pipeline & function for data engineering    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf4ddf1d-2a9c-44e5-b139-8a3039f6eff6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# !pip install pyspark\n",
    "# pip install synapseml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75e809fa-c387-4877-9827-0dc4c14cc387",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np; np.__version__ = '1.24.0'\n",
    "import shap\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # for data visualization purposes\n",
    "import seaborn as sns # for statistical data visualization\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "# Fit and transform the data\n",
    "\n",
    "# from pyspark.sql import SparkSession\n",
    "# spark = SparkSession.builder.appName(\"example\").getOrCreate()\n",
    "\n",
    "\n",
    "# def display(df):\n",
    "#     \"\"\"\n",
    "#     Mimics Databricks' display() function by converting a Spark DataFrame to Pandas \n",
    "#     and displaying it nicely in Jupyter notebooks.\n",
    "    \n",
    "#     Args:\n",
    "#         df (pyspark.sql.DataFrame): The Spark DataFrame to display.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         from IPython.display import display as ipy_display\n",
    "#         ipy_display(df.toPandas())  # Convert to Pandas and display\n",
    "#     except:\n",
    "#         print(df.show())  # Fallback to show() if Pandas conversion fails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a3639b1-26a4-47bc-8c82-a84b7c51bbf1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Pipeline_Data_ Engineering"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, MinMaxScaler, VectorAssembler\n",
    "\n",
    "# Step 1: StringIndexer for categorical columns\n",
    "sex_indexer = StringIndexer(inputCol=\"sex\", outputCol=\"sex_index\")\n",
    "smoker_indexer = StringIndexer(inputCol=\"smoker\", outputCol=\"smoker_index\")\n",
    "region_indexer = StringIndexer(inputCol=\"region\", outputCol=\"region_index\")\n",
    "\n",
    "# Step 2: OneHotEncoder for region\n",
    "region_encoder = OneHotEncoder(inputCol=\"region_index\", outputCol=\"region_encoded\")\n",
    "\n",
    "# Step 3: VectorAssembler to combine \"bmi\" for MinMaxScaler\n",
    "bmi_assembler = VectorAssembler(inputCols=[\"bmi\"], outputCol=\"bmi_assembled\")\n",
    "age_assembler = VectorAssembler(inputCols=[\"age\"], outputCol=\"age_assembled\")\n",
    "\n",
    "# Step 4: MinMaxScaler for normalization\n",
    "bmi_scaler = MinMaxScaler(inputCol=\"bmi_assembled\", outputCol=\"bmi_normalized\")\n",
    "age_scaler = MinMaxScaler(inputCol=\"age_assembled\", outputCol=\"age_normalized\")\n",
    "\n",
    "# Step 5: Create Pipeline\n",
    "pipeline = Pipeline(stages=[\n",
    "    sex_indexer, smoker_indexer, region_indexer, region_encoder,  # Categorical encoding\n",
    "    bmi_assembler, bmi_scaler,  # bmi normalization\n",
    "    age_assembler, age_scaler   # age normalization\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ecea318-cf67-4d29-bf76-29e48d689943",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "VectorAssembler"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "def vectorize_features(df_transformed):\n",
    "    # Step 1: Select the features to vectorize\n",
    "    input_columns = [\"sex_index\", \"smoker_index\", \"region_encoded\", \"bmi_normalized\", \"age_normalized\", \"children\"]\n",
    "\n",
    "    # Step 2: Create a new VectorAssembler to combine features\n",
    "    assembler = VectorAssembler(inputCols=input_columns, outputCol=\"features\")\n",
    "\n",
    "    # Step 3: Rename expenses to label\n",
    "    df_transformed = df_transformed.withColumnRenamed(\"expenses\", \"label\")\n",
    "\n",
    "    # Step 4: Vectorize the features using VectorAssembler\n",
    "    df_vector = assembler.transform(df_transformed)\n",
    "    df_final = df_vector.select(\"label\", \"features\")\n",
    "\n",
    "    return df_final\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Common_Function",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}